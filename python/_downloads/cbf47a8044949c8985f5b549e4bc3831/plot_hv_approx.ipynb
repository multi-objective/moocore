{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Comparing methods for approximating the hypervolume\n\nThe following examples compare various ways of approximating the hypervolume of\na nondominated set.\n\n## Comparing HypE and DZ2019\n\nThis example shows how to approximate the hypervolume metric of the\n``CPFs.txt`` dataset using both :func:`moocore.whv_hype()` (HypE), and\n:func:`moocore.hv_approx()` (DZ2019) for several values of the number of\nsamples between $10^1$ and $10^5$.  We repeat each calculation 10\ntimes to account for stochasticity.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport moocore"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First calculate the exact hypervolume.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ref = 2.1\nx = moocore.get_dataset(\"CPFs.txt\")[:, :-1]\nx = moocore.filter_dominated(x)\nx = moocore.normalise(x, to_range=[1, 2])\ntrue_hv = moocore.hypervolume(x, ref=ref)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, we approximate the hypervolume using $\\{10^1, 10^2, \\ldots,\n10^5\\}$ random samples to show the higher samples reduce the approximation\nerror. Since the approximation is stochastic, we perform 10 repetitions of\neach computation.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "nreps = 10\nnsamples_exp = 5\nrng1 = np.random.default_rng(42)\nrng2 = np.random.default_rng(42)\nresults = {\"HypE\": {}, \"DZ2019-HW\": {}, \"DZ2019-MC\": {}}\nfor i in range(1, nsamples_exp + 1):\n    for what in results.keys():\n        results[what][i] = []\n\n    res = moocore.hv_approx(x, ref=ref, nsamples=10**i, method=\"DZ2019-HW\")\n    results[\"DZ2019-HW\"][i].append(res)\n\n    for r in range(nreps):\n        res = moocore.whv_hype(x, ref=ref, ideal=0, nsamples=10**i, seed=rng1)\n        results[\"HypE\"][i].append(res)\n        res = moocore.hv_approx(\n            x, ref=ref, nsamples=10**i, seed=rng2, method=\"DZ2019-MC\"\n        )\n        results[\"DZ2019-MC\"][i].append(res)\n\nwidth = len(\"Mean DZ2019-MC\")\ntext = \"True HV\"\nprint(f\"{text:>{width}} : {true_hv:.5f}\")\nfor what in results.keys():\n    res = results[what][nsamples_exp]\n    text = \"Mean \" + what\n    print(\n        f\"{text:>{width}} : {np.mean(res):.5f} [{np.min(res):.5f}, {np.max(res):.5f}]\"\n    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, we plot the results.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "df = [\n    pd.DataFrame(results[what]).assign(Method=what) for what in results.keys()\n]\n\ndf = (\n    pd.concat(df)\n    .reset_index(names=\"rep\")\n    .melt(id_vars=[\"rep\", \"Method\"], var_name=\"samples\")\n)\ndf[\"samples\"] = 10 ** df[\"samples\"]\ndf[\"value\"] = np.abs(df[\"value\"] - true_hv) / true_hv\n\nax = sns.lineplot(x=\"samples\", y=\"value\", hue=\"Method\", data=df, marker=\"o\")\nax.set(xscale=\"log\", yscale=\"log\", ylabel=\"Relative error\")\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Comparing Monte-Carlo and quasi-Monte-Carlo approximations\n\nThe quasi-Monte-Carlo approximation with ``method=DZ2019-HW`` is\ndeterministic, but not monotonic on the number of samples. Nevertheless, it\ntends to be better than the Monte-Carlo approximation generated with\n``method=DZ2019-MC``, specially with large number of objectives.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "datasets = [\"DTLZLinearShape.8d.front.60pts.10\", \"ran.10pts.9d.10\"]\nref = 10\nsamples = 2 ** np.arange(12, 20)\nmaxiter = samples.max()\n\nfor dataset in datasets:\n    x = moocore.get_dataset(dataset)[:, :-1]\n    x = moocore.filter_dominated(x)\n    exact = moocore.hypervolume(x, ref=ref)\n\n    res = []\n    for i in samples:\n        hv = moocore.hv_approx(x, ref=ref, nsamples=i, method=\"DZ2019-HW\")\n        res.append(dict(samples=i, method=\"HW\", hv=hv))\n\n    for k in range(16):\n        seed = k\n        for i in samples:\n            hv = moocore.hv_approx(\n                x, ref=ref, nsamples=i, method=\"DZ2019-MC\", seed=seed\n            )\n            res.append(dict(samples=i, method=\"MC\", hv=hv))\n\n    df = pd.DataFrame(res)\n    df[\"hverror\"] = np.abs(1.0 - (df.hv / exact))\n    df[\"method\"] = df[\"method\"].astype(\"category\")\n\n    plt.figure()\n    ax = sns.lineplot(\n        data=df, x=\"samples\", y=\"hverror\", hue=\"method\", marker=\"o\"\n    )\n    ax.set_title(f\"{dataset}\", fontsize=10)\n    ax.set(yscale=\"log\", ylabel=\"Relative error\")\n    ax.set_xscale(\"log\", base=2)\n    plt.tight_layout()\n\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}